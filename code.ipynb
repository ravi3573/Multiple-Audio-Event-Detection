{"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#IMPORTING the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython import display as ipd\nfrom glob import glob\nimport librosa\nimport seaborn as sns\nimport librosa.display\nimport skimage.io\nimport os","metadata":{"id":"hzn-1DwZMuh_","execution":{"iopub.status.busy":"2023-08-18T21:53:51.159756Z","iopub.execute_input":"2023-08-18T21:53:51.160149Z","iopub.status.idle":"2023-08-18T21:53:54.461699Z","shell.execute_reply.started":"2023-08-18T21:53:51.160071Z","shell.execute_reply":"2023-08-18T21:53:54.460281Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n# Multihot to eventroll function\ndef eventroll_to_multihot_vector(eventroll):\n    \"\"\"\n    Parameters\n    ----------\n    eventroll : np.array\n        Eventroll matrix of shape=(11, 1000).\n    \n    Returns\n    -------\n    np.array\n        A multihot vector of shape=(10,)\n    \"\"\"\n    \n    # findout active events:\n    active_events = (eventroll.sum(axis=1) >= 0.5).astype('float')\n    \n    # remove silence class:\n    return np.delete(active_events, 8)\n","metadata":{"id":"ASuDkTtYMSYv","execution":{"iopub.status.busy":"2023-08-18T21:53:54.464590Z","iopub.execute_input":"2023-08-18T21:53:54.465385Z","iopub.status.idle":"2023-08-18T21:53:54.473513Z","shell.execute_reply.started":"2023-08-18T21:53:54.465340Z","shell.execute_reply":"2023-08-18T21:53:54.471956Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Making the numpy array of X input\nX=np.zeros((10000,64,1000))\ni=0\ndir_name=\"../input/assigement2-data/X\"\nfor filename in os.listdir(\"../input/assigement2-data/X\"):\n    #print(filename)\n    file_path=\"../input/assigement2-data/X\"+filename\n    file=np.load(os.path.join(dir_name, filename))\n    i=i+1\n    sz=len(filename)\n    j=0\n    num=0\n    while(filename[j]!='_'):\n      j=j+1\n    j=j+1\n    while(j<sz-4):\n      num=num*10+int(ord(filename[j])-ord('0'))\n      j=j+1\n    X[num]=file[0]\n ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuASXgFdT2YK","outputId":"1e3bf776-e527-49e9-9729-30782387a5e1","execution":{"iopub.status.busy":"2023-08-18T21:53:54.475373Z","iopub.execute_input":"2023-08-18T21:53:54.476079Z","iopub.status.idle":"2023-08-18T21:54:53.949631Z","shell.execute_reply.started":"2023-08-18T21:53:54.476038Z","shell.execute_reply":"2023-08-18T21:54:53.948511Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(X.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4q_ql29EAxeM","outputId":"a172f29d-e58d-42f6-95d4-2d98dccfcc2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Y input \nY=np.zeros((10000,10))\ni=0\ndir_name2=\"../input/assigement2-data/Y\"\nfor filename in os.listdir(\"../input/assigement2-data/Y\"):\n    # print(filename)\n    file_path=\"../input/assigement2-data/Y\"+filename\n    file=np.load(os.path.join(dir_name2, filename))\n    # labels.append(eventroll_to_multihot_vector(file))\n    i=i+1\n    sz=len(filename)\n    j=0\n    num=0\n    while(filename[j]!='_'):\n      j=j+1\n    j=j+1\n    while(j<sz-4):\n      num=num*10+int(ord(filename[j])-ord('0'))\n      j=j+1\n    Y[num]=eventroll_to_multihot_vector(file)\n","metadata":{"id":"rRKnMAM4T2ai","execution":{"iopub.status.busy":"2023-08-18T21:54:53.954713Z","iopub.execute_input":"2023-08-18T21:54:53.955027Z","iopub.status.idle":"2023-08-18T21:55:35.213165Z","shell.execute_reply.started":"2023-08-18T21:54:53.954998Z","shell.execute_reply":"2023-08-18T21:55:35.212144Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(Y[0].shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lamGGoURT2u3","outputId":"4159d89e-106d-4136-ed31-643404d5002b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the Specific class for checking imbalance\ncount=0\nfor i in range(1000):\n    flag=0;\n    for j in range(10):\n        if(Y[i][j]==1 and j==8):\n            flag=1\n    if(flag):\n        count=count+1\nprint(count)  ","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:55:35.215446Z","iopub.execute_input":"2023-08-18T21:55:35.216129Z","iopub.status.idle":"2023-08-18T21:55:35.233631Z","shell.execute_reply.started":"2023-08-18T21:55:35.216073Z","shell.execute_reply":"2023-08-18T21:55:35.232361Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"923\n","output_type":"stream"}]},{"cell_type":"code","source":"# for i in (list_y):\n#   print(i)","metadata":{"id":"-0__GDykFbng","execution":{"iopub.status.busy":"2023-08-18T21:55:45.032689Z","iopub.execute_input":"2023-08-18T21:55:45.033067Z","iopub.status.idle":"2023-08-18T21:55:45.037452Z","shell.execute_reply.started":"2023-08-18T21:55:45.033034Z","shell.execute_reply":"2023-08-18T21:55:45.036169Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# import librosa\n# import librosa.display\n# S_db = librosa.amplitude_to_db(arr_x[0], ref=np.max)\n# plt.figure()\n# librosa.display.specshow(S_db)\n# plt.colorbar()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"8clJmwXeUDwG","outputId":"1e49dbd3-03d1-447a-b7ed-44eefe7fb359","execution":{"iopub.status.busy":"2023-08-18T21:55:57.554151Z","iopub.execute_input":"2023-08-18T21:55:57.554774Z","iopub.status.idle":"2023-08-18T21:55:57.559698Z","shell.execute_reply.started":"2023-08-18T21:55:57.554731Z","shell.execute_reply":"2023-08-18T21:55:57.558698Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Making the train test split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=100)","metadata":{"id":"2vEnRXu6CWsu","execution":{"iopub.status.busy":"2023-08-18T21:56:00.115493Z","iopub.execute_input":"2023-08-18T21:56:00.116011Z","iopub.status.idle":"2023-08-18T21:56:05.438105Z","shell.execute_reply.started":"2023-08-18T21:56:00.115967Z","shell.execute_reply":"2023-08-18T21:56:05.433129Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Reshaping the data \nX_train = X_train.reshape(8000,64, 1000, 1)\nX_test = X_test.reshape(2000,64, 1000, 1)\nX_train = X_train.astype('float32')\nX_test= X_test.astype('float32')","metadata":{"id":"yMPmI95-Fzbr","execution":{"iopub.status.busy":"2023-08-18T21:56:12.544566Z","iopub.execute_input":"2023-08-18T21:56:12.545068Z","iopub.status.idle":"2023-08-18T21:56:15.678781Z","shell.execute_reply.started":"2023-08-18T21:56:12.545025Z","shell.execute_reply":"2023-08-18T21:56:15.677663Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LORB15dGGTR4","outputId":"4bb6cad7-c747-4585-f6cc-618afa812077","execution":{"iopub.status.busy":"2023-08-18T21:55:35.424206Z","iopub.status.idle":"2023-08-18T21:55:35.424789Z","shell.execute_reply.started":"2023-08-18T21:55:35.424523Z","shell.execute_reply":"2023-08-18T21:55:35.424547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras.backend as K\nimport tensorflow as tf\ndef get_f1(y_true, y_hat): #taken from old keras source code\n    f1s = [0, 0, 0]\n\n    y_true = tf.cast(y_true, tf.float64)\n    y_pred = tf.cast(y_hat, tf.float64)\n\n    for i, axis in enumerate([None, 0]):\n        TP = tf.count_nonzero(y_pred * y_true, axis=axis)\n        FP = tf.count_nonzero(y_pred * (y_true - 1), axis=axis)\n        FN = tf.count_nonzero((y_pred - 1) * y_true, axis=axis)\n\n        precision = TP / (TP + FP)\n        recall = TP / (TP + FN)\n        f1 = 2 * precision * recall / (precision + recall)\n\n        f1s[i] = tf.reduce_mean(f1)\n\n    weights = tf.reduce_sum(y_true, axis=0)\n    weights /= tf.reduce_sum(weights)\n\n    f1s[2] = tf.reduce_sum(f1 * weights)\n\n    micro, macro, weighted = f1s\n    return micro, macro, weighted","metadata":{"id":"BdTYbrycGgWT","execution":{"iopub.status.busy":"2023-08-18T21:56:23.585394Z","iopub.execute_input":"2023-08-18T21:56:23.585780Z","iopub.status.idle":"2023-08-18T21:56:29.630781Z","shell.execute_reply.started":"2023-08-18T21:56:23.585748Z","shell.execute_reply":"2023-08-18T21:56:29.629656Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Library for focal loss\n! pip install focal_loss","metadata":{"id":"h6eNMic78tiv","execution":{"iopub.status.busy":"2023-08-18T21:56:34.730609Z","iopub.execute_input":"2023-08-18T21:56:34.731264Z","iopub.status.idle":"2023-08-18T21:57:08.013038Z","shell.execute_reply.started":"2023-08-18T21:56:34.731227Z","shell.execute_reply":"2023-08-18T21:57:08.011754Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting focal_loss\n  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\nRequirement already satisfied: tensorflow>=2.2 in /opt/conda/lib/python3.7/site-packages (from focal_loss) (2.6.4)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (0.37.1)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (0.4.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (0.15.0)\nCollecting typing-extensions<3.11,>=3.7\n  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (3.19.4)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.43.0)\nRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (2.6.0)\nCollecting tensorboard<2.7,>=2.6.0\n  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\nRequirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (2.6.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.12)\nRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (5.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal_loss) (1.12.1)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow>=2.2->focal_loss) (1.5.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (3.3.7)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (0.6.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (1.35.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (1.8.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (59.8.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (0.4.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (2.28.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (2.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (4.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (4.13.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.2->focal_loss) (3.2.0)\nInstalling collected packages: typing-extensions, numpy, h5py, tensorboard, focal_loss\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.1.1\n    Uninstalling typing_extensions-4.1.1:\n      Successfully uninstalled typing_extensions-4.1.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.6\n    Uninstalling numpy-1.21.6:\n      Successfully uninstalled numpy-1.21.6\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Uninstalling h5py-3.7.0:\n      Successfully uninstalled h5py-3.7.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.10.1\n    Uninstalling tensorboard-2.10.1:\n      Successfully uninstalled tensorboard-2.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ndask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nxarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\nrich 12.6.0 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.7.7 requires tensorboard>=2.9.1, but you have tensorboard 2.6.0 which is incompatible.\npytorch-lightning 1.7.7 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytools 2022.1.12 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nnnabla 1.31.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\njaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\njax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\nflax 0.6.1 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\nfeaturetools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\ndask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\ndask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\ncmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\nallennlp 2.10.1 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\nallennlp 2.10.1 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\naioitertools 0.11.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.93 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed focal_loss-0.0.7 h5py-3.1.0 numpy-1.19.5 tensorboard-2.6.0 typing-extensions-3.10.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#Making the CNN Based Model\nimport keras\nfrom keras import regularizers, activations\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom focal_loss import BinaryFocalLoss\n\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(24, (3, 3), activation='relu', input_shape=(64, 1000, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(48, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(layers.Dense(300, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(layers.Dense(200, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='sigmoid'))\n\nmodel.compile(loss=BinaryFocalLoss(gamma=2), metrics=[keras.metrics.BinaryAccuracy()], optimizer='adam')","metadata":{"id":"E8rcxrcTGn7u","execution":{"iopub.status.busy":"2023-08-18T21:57:20.207964Z","iopub.execute_input":"2023-08-18T21:57:20.208408Z","iopub.status.idle":"2023-08-18T21:57:24.596122Z","shell.execute_reply.started":"2023-08-18T21:57:20.208370Z","shell.execute_reply":"2023-08-18T21:57:24.595021Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8JjixTVJeGQ","outputId":"bb750254-81d1-4e7e-ac20-a82cb07a955f","execution":{"iopub.status.busy":"2023-08-18T21:57:35.177572Z","iopub.execute_input":"2023-08-18T21:57:35.177959Z","iopub.status.idle":"2023-08-18T21:57:35.191081Z","shell.execute_reply.started":"2023-08-18T21:57:35.177928Z","shell.execute_reply":"2023-08-18T21:57:35.185994Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 62, 998, 24)       240       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 499, 24)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 29, 497, 32)       6944      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 248, 32)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 12, 246, 48)       13872     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 123, 48)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 4, 121, 64)        27712     \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 64)                0         \n_________________________________________________________________\ndense (Dense)                (None, 300)               19500     \n_________________________________________________________________\ndropout (Dropout)            (None, 300)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 200)               60200     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                2010      \n=================================================================\nTotal params: 130,478\nTrainable params: 130,478\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime \nnum_epochs = 200\nnum_batch_size = 4\nstart = datetime.now()\nhistory = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"id":"XH7D5agwJh7Z","outputId":"b925d7ae-a7c3-4634-83bb-1c362d9790c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving the  model\nmodel.save(\"assigement2_f3.h5\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjB-1oTCcXnL","outputId":"2bfd4988-dc47-4d33-b9ea-3afe9f51f8d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the model\nfrom matplotlib import pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat=model.predict(X_test)","metadata":{"id":"9N39oWHbekDn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8408dfe-6275-4b98-9dab-5f95d7c9bcda","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat=y_hat.round()","metadata":{"id":"Fa_jTnyOwqPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst=[0,0,0,0,0,0,0,0,0,0]\nfor i in range(400):\n  for j in range(10):\n    print(y_hat[i][j])\n    print(y_test[i][j])\n    if(y_hat[i][j]==y_test[i][j]):\n       lst[j]=lst[j]+1\nfor j in lst:\n  print(j/400)","metadata":{"id":"xgpUzThTwugt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in lst:\n  print(j/400)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6YYQHS8xi8i","outputId":"bf556994-e4f7-4260-a326-064642e73d7e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst90=[0,0,0,0,0,0,0,0,0,0]\nlst91=[0,0,0,0,0,0,0,0,0,0]\nfor i in range(400):\n  for j in range(10):\n    lst90[j]=lst90[j]+y_hat[i][j]\n    lst91[j]=lst91[j]+y_test[i][j]\n","metadata":{"id":"QVA2auC7ymGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lst90)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a10lEwiby6fe","outputId":"7a1759a3-f33d-41ed-e27f-9e2db7d5995f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst91","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbdGqcz7y8Le","outputId":"5cde9b47-82fb-4a89-f631-30e238b1c10a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat[6]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qj8VDxP09iyM","outputId":"5b582a41-2e2e-4547-cb83-8c0d579a5fd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,400):\n  flag=1\n  for j in range(0,10):\n    if(y_hat[0][j] != y_hat[i][j]):\n      flag=0\n  count=count+flag\nprint(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QPR2_0drzToc","outputId":"7a5e71fd-6eab-4bf2-a870-8d6c83200e94"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Validation step***","metadata":{}},{"cell_type":"code","source":"val_x={}\nlist_valx=[]\ni=0\ndir_name2=\"../input/validation/dataset/X\"\nfor filename in os.listdir(\"../input/validation/dataset/X\"):\n    #print(filename)\n    file_path=\"../input/validation/dataset/X\"+filename\n    file=np.load(os.path.join(dir_name2, filename))\n    i=i+1\n    sz=len(filename)\n    j=0\n    num=0\n    while(filename[j]!='_'):\n      j=j+1\n    j=j+1\n    while(j<sz-4):\n      num=num*10+int(ord(filename[j])-ord('0'))\n      j=j+1\n    val_x[num]=file[0]\n    list_valx.append(num)\n    #print(num)\n \nprint(len(val_x))\n","metadata":{"id":"fRfOPg5oFupX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(list_valx))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mG6OfIUNG05R","outputId":"814eb366-fd32-4756-ff24-d2771a07fce3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_y={}\ni=0\nlist_valy=[]\ndir_name3=\"../input/validation/dataset/Y\"\nfor filename in os.listdir(\"../input/validation/dataset/Y\"):\n    # print(filename)\n    file_path=\"../input/validation/dataset/Y\"+filename\n    file=np.load(os.path.join(dir_name3, filename))\n    # labels.append(eventroll_to_multihot_vector(file))\n    i=i+1\n    sz=len(filename)\n    j=0\n    num=0\n    while(filename[j]!='_'):\n      j=j+1\n    j=j+1\n    while(j<sz-4):\n      num=num*10+int(ord(filename[j])-ord('0'))\n      j=j+1\n    val_y[num]=eventroll_to_multihot_vector(file)\n    list_valy.append(num)\n","metadata":{"id":"SEh9-UHjHCvC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(val_y))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrwNmaImIF8g","outputId":"75375ea1-05f2-4092-c1ab-1cc2f80bcc2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val=[]\ny_val=[]\nfor i in list_valx:\n  x_val.append(val_x[i])\n  y_val.append(val_y[i])","metadata":{"id":"NUVpbKHkHl_o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(x_val))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OgBOr5XYwZ7","outputId":"6f3a2a6d-2af1-4f20-8bd1-95c37846f428","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val=np.array(x_val)\nx_val = x_val.reshape(2000,64, 1000, 1)\n","metadata":{"id":"SCYAsYT6H6GE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom focal_loss import BinaryFocalLoss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =  keras.models.load_model(\"../input/parametrs/assigement2_f.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred = model.predict(x_val)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8eLQmMk7KezC","outputId":"d61e8a6e-40ef-45c4-a908-2d9a733c3df7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred=val_pred.round()","metadata":{"id":"159PkZISLZyf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst000=[0,0,0,0,0,0,0,0,0,0]\nlst001=[0,0,0,0,0,0,0,0,0,0]\nfor i in range(2000):\n  for j in range(10):\n    lst000[j]=lst000[j]+val_pred[i][j]\n    lst001[j]=lst001[j]+y_val[i][j]","metadata":{"id":"2sV9gvEBLHNS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst000","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JlRO6tcLWTq","outputId":"93eab618-1fcc-4d5b-9585-93433a4e37dc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst001","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qBwlF05LXow","outputId":"26ceaae2-418d-4017-ba9c-1030cdc32615","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\n\nprint(precision_score(val_pred,y_val,average=\"samples\"))\nprint(recall_score(val_pred,y_val,average=\"samples\"))\nprint(f1_score(val_pred,y_val,average=\"samples\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\nmultilabel_confusion_matrix(y_val, val_pred)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYMsyr83Li-Y","outputId":"ed8c32b1-9839-4c29-cb65-d524b4059859","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_val, val_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIqZasO_Tlfe","outputId":"838415e0-6fc2-4646-87c0-b9ff70eb3d79","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst12=[0,0,0,0,0,0,0,0,0,0]\ncount=0\nfor i in range(2000):\n  for j in range(10):\n    if(val_pred[i][j]==y_val[i][j]):\n       lst12[j]=lst12[j]+1\n\nfor i in range(2000):\n  flag=1\n  for j in range(10):\n    if(val_pred[i][j]!=y_val[i][j]):\n       flag=0\n  count=count+flag\n\nfor j in lst12:\n  print(j/2000)\nprint(\"final ccc\")\nprint(count/2000)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNF58OB7VT1Z","outputId":"a735becc-5337-47e3-95c7-28fef00b5165","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install focal_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import regularizers, activations\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom focal_loss import BinaryFocalLoss\nmodel =  keras.models.load_model(\"../input/parametrs/assigement2_f.h5\")","metadata":{"id":"sRPJb4cI0tG_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred1 = model.predict(x_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred1=val_pred1.round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst000=[0,0,0,0,0,0,0,0,0,0]\nlst001=[0,0,0,0,0,0,0,0,0,0]\nfor i in range(2000):\n  for j in range(10):\n    lst000[j]=lst000[j]+val_pred1[i][j]\n    lst001[j]=lst001[j]+y_val[i][j]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst001","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\n\nprint(precision_score(val_pred1,y_val,average=\"samples\"))\nprint(recall_score(val_pred1,y_val,average=\"samples\"))\nprint(f1_score(val_pred1,y_val,average=\"samples\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\nmultilabel_confusion_matrix(y_val, val_pred1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_val, val_pred1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst13=[0,0,0,0,0,0,0,0,0,0]\ncount=0\nfor i in range(2000):\n  for j in range(10):\n    if(val_pred1[i][j]==y_val[i][j]):\n       lst13[j]=lst13[j]+1\n\nfor i in range(2000):\n  flag=1\n  for j in range(10):\n    if(val_pred1[i][j]!=y_val[i][j]):\n       flag=0\n  count=count+flag\n\nfor j in lst13:\n  print(j/2000)\nprint(\"final ccc\")\nprint(count/2000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # ***Making Prediction***","metadata":{}},{"cell_type":"code","source":"! pip install focal_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import regularizers, activations\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom focal_loss import BinaryFocalLoss\nmodel =  keras.models.load_model(\"../input/parametrs/assigement2_f.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x={}\nlist_testx=[]\nfname=[]\ni=0\ndir_name2=\"../input/ass2-test-data/test/X\"\nfor filename in os.listdir(\"../input/ass2-test-data/test/X\"):\n    #print(filename)\n    file_path=\"../input/ass2-test-data/test/X\"+filename\n    file=np.load(os.path.join(dir_name2, filename))\n    i=i+1\n    sz=len(filename)\n    j=0\n    num=0\n    while(filename[j]!='_'):\n      j=j+1\n    j=j+1\n    while(j<sz-4):\n      num=num*10+int(ord(filename[j])-ord('0'))\n      j=j+1\n    test_x[num]=file[0]\n    list_testx.append(num)\n    fname.append(filename)\n    #print(num)\n \nprint(len(test_x))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y={}\ni=0\nlist_valy=[]\ndir_name3=\"../input/groud-truth/lables_test\"\nfor filename in os.listdir(\"../input/groud-truth/lables_test\"):\n    # print(filename)\n    file_path=\"../input/groud-truth/lables_test\"+filename\n    file=np.load(os.path.join(dir_name3, filename))\n    # labels.append(eventroll_to_multihot_vector(file))\n    i=i+1\n    sz=len(filename)\n    j=0\n    num=0\n    while(filename[j]!='_'):\n      j=j+1\n    j=j+1\n    while(j<sz-4):\n      num=num*10+int(ord(filename[j])-ord('0'))\n      j=j+1\n    test_y[num]=eventroll_to_multihot_vector(file)\n    list_valy.append(num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test=[]\ny_test=[]\nfor i in list_testx:\n    x_test.append(test_x[i])\n    y_test.append(test_y[i])\n  \n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test=np.array(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test=np.array(x_test)\nx_test = x_test.reshape(2500,64, 1000, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predictions.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=predictions.round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in predictions:\n    print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst100=[0,0,0,0,0,0,0,0,0,0]\nlst101=[0,0,0,0,0,0,0,0,0,0]\nfor i in range(2500):\n  for j in range(10):\n    lst100[j]=lst100[j]+predictions[i][j]\n    lst101[j]=lst101[j]+y_test[i][j]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst101","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\n\nprint(precision_score(predictions,y_test,average=\"samples\"))\nprint(recall_score(predictions,y_test,average=\"samples\"))\nprint(f1_score(predictions,y_test,average=\"samples\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import argmax\npreds=[]\nannotate = ['Alarm_bell_ringing','Blender','Cat','Dishes','Dog','Electric_shaver_toothbrush','Frying','Running_water','Speech','Vacuum_cleaner']\nfor p in predictions:\n    one = []\n    for i in range(0,10):\n        if p[i]==1:\n            one.append(annotate[i])\n    if(len(one)==0):\n        one.append('Silence')\n    one = np.array(one)\n    preds.append(one)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\nmultilabel_confusion_matrix(y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst13=[0,0,0,0,0,0,0,0,0,0]\ncount=0\nfor i in range(2000):\n  for j in range(10):\n    if(predictions[i][j]==y_test[i][j]):\n       lst13[j]=lst13[j]+1\n\nfor i in range(2000):\n  flag=1\n  for j in range(10):\n    if(predictions[i][j]!=y_test[i][j]):\n       flag=0\n  count=count+flag\n\nfor j in lst13:\n  print(j/2000)\nprint(\"final ccc\")\nprint(count/2000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in preds:\n    print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame({\"fname\" : fname, \"predictions\" : preds})\ndf1.to_csv(\"ass2_submission_f.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}